{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample of training the titanic data sets and creating a submission using AutoML \n",
    "# for the popular Kaggle Titanic challenge. Note: this has no feature engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below to Install azureml.core in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m  pip install azureml.core --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below to Install azureml.train.automl in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m  pip install azureml.train.automl --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"**add azure subscription ID here**\"\n",
    "resource_group = \"auto-ml-local\"\n",
    "workspace_name = \"kappgle-ml-local\"\n",
    "workspace_region = \"eastus2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'applicationInsights': '/subscriptions/c8a23972-1b42-43fa-9bda-92e665014f30/resourcegroups/auto-ml-local/providers/microsoft.insights/components/kappgleminsightsswmwdewl',\n",
       " 'containerRegistry': '/subscriptions/c8a23972-1b42-43fa-9bda-92e665014f30/resourcegroups/auto-ml-local/providers/microsoft.containerregistry/registries/kappglemacrvuatnpjh',\n",
       " 'creationTime': '2019-02-11T00:06:12.4721271+00:00',\n",
       " 'description': '',\n",
       " 'friendlyName': 'kappgle-ml-local',\n",
       " 'id': '/subscriptions/c8a23972-1b42-43fa-9bda-92e665014f30/resourceGroups/auto-ml-local/providers/Microsoft.MachineLearningServices/workspaces/kappgle-ml-local',\n",
       " 'identityPrincipalId': 'c037cc6f-9b6d-4abb-b237-0927801f8514',\n",
       " 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'keyVault': '/subscriptions/c8a23972-1b42-43fa-9bda-92e665014f30/resourcegroups/auto-ml-local/providers/microsoft.keyvault/vaults/kappglemkeyvaultuirqpheu',\n",
       " 'location': 'eastus2',\n",
       " 'name': 'kappgle-ml-local',\n",
       " 'storageAccount': '/subscriptions/c8a23972-1b42-43fa-9bda-92e665014f30/resourcegroups/auto-ml-local/providers/microsoft.storage/storageaccounts/kappglemstorageiskjuwas',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'workspaceid': '953614a2-6003-4f35-a62c-1f1b6bcfedde'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Workspace class and check the Azure ML SDK version.\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = workspace_region,\n",
    "                      exist_ok=True)\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>eastus2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Directory</th>\n",
       "      <td>./automated-ml-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>auto-ml-local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>c8a23972-1b42-43fa-9bda-92e665014f30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>kappgle-ml-local</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       \n",
       "Location           eastus2                             \n",
       "Project Directory  ./automated-ml-classification       \n",
       "Resource Group     auto-ml-local                       \n",
       "SDK version        1.0.10                              \n",
       "Subscription ID    c8a23972-1b42-43fa-9bda-92e665014f30\n",
       "Workspace          kappgle-ml-local                    "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.core\n",
    "import pandas as pd\n",
    "from azureml.core.workspace import Workspace\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# ws = Workspace.from_config()\n",
    "# choose a name for the run history container in the workspace\n",
    "experiment_name = 'automated-ml-classification'\n",
    "# project folder\n",
    "project_folder = './automated-ml-classification'\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.DataFrame(data=output, index=['']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "#get the titanic training data set\n",
    "url = \"https://raw.githubusercontent.com/TheovanKraay/mldata/master/titanic-train.csv\"\n",
    "titanic = pandas.read_csv(url)\n",
    "dflow_X = titanic[['Sex', 'Age', 'SibSp', 'Parch', 'Embarked']]\n",
    "dflow_y = titanic['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the dataset\n",
    "x_df = dflow_X\n",
    "y_df = dflow_y\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure AutoML settings\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\" : 10,\n",
    "    \"iterations\" : 30,\n",
    "    \"primary_metric\" : 'accuracy',\n",
    "    \"preprocess\" : True,\n",
    "    \"verbosity\" : logging.INFO,\n",
    "    \"n_cross_validations\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# local compute - set the parameters\n",
    "automated_ml_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automated_ml_errors.log',\n",
    "                             path = project_folder,\n",
    "                             X = x_train.values,\n",
    "                             y = y_train.values.flatten(),\n",
    "                             **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_bbeb1a3f-e4ca-47a5-a309-af66c25a0470\n",
      "*******************************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "TRAINFRAC: Fraction of the training data to train on.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "*******************************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       TRAINFRAC  DURATION      METRIC      BEST\n",
      "         0   TruncatedSVDWrapper RandomForest               1.0000     0:00:40       0.8034    0.8034\n",
      "         1   TruncatedSVDWrapper LogisticRegression         1.0000     0:00:17       0.7767    0.8034\n",
      "         2   MaxAbsScaler LogisticRegression                1.0000     0:00:18       0.7851    0.8034\n",
      "         3   MaxAbsScaler RandomForest                      1.0000     0:00:46       0.7641    0.8034\n",
      "         4   MaxAbsScaler LinearSVM                         1.0000     0:00:20       0.7823    0.8034\n",
      "         5   MaxAbsScaler LightGBM                          1.0000     0:00:26       0.7851    0.8034\n",
      "         6   TruncatedSVDWrapper GradientBoosting           1.0000     0:00:29       0.7668    0.8034\n",
      "         7   MaxAbsScaler LogisticRegression                1.0000     0:00:16       0.7851    0.8034\n",
      "         8   SparseNormalizer LightGBM                      1.0000     0:00:20       0.6502    0.8034\n",
      "         9   StandardScalerWrapper ExtremeRandomTrees       1.0000     0:00:34       0.7795    0.8034\n",
      "        10   StandardScalerWrapper GradientBoosting         1.0000     0:00:23       0.6307    0.8034\n",
      "        11   TruncatedSVDWrapper GradientBoosting           1.0000     0:00:23       0.7823    0.8034\n",
      "        12   TruncatedSVDWrapper GradientBoosting           1.0000     0:00:35       0.7964    0.8034\n",
      "        13   MaxAbsScaler RandomForest                      1.0000     0:00:22       0.7795    0.8034\n",
      "        14   TruncatedSVDWrapper LogisticRegression         1.0000     0:00:15       0.7823    0.8034\n",
      "        15   SparseNormalizer LogisticRegression            1.0000     0:00:15       0.7781    0.8034\n",
      "        16   TruncatedSVDWrapper ExtremeRandomTrees         1.0000     0:00:36       0.7402    0.8034\n",
      "        17   StandardScalerWrapper LightGBM                 1.0000     0:00:18       0.7247    0.8034\n",
      "        18   SparseNormalizer LogisticRegression            1.0000     0:00:17       0.6896    0.8034\n",
      "        19   MaxAbsScaler LogisticRegression                1.0000     0:00:14       0.7879    0.8034\n",
      "        20   SparseNormalizer LinearSVM                     1.0000     0:00:16       0.7064    0.8034\n",
      "        21   SparseNormalizer ExtremeRandomTrees            1.0000     0:00:16       0.6082    0.8034\n",
      "        22   StandardScalerWrapper LogisticRegression       1.0000     0:00:14       0.7879    0.8034\n",
      "        23   MaxAbsScaler LightGBM                          1.0000     0:00:18       0.7823    0.8034\n",
      "        24   StandardScalerWrapper LogisticRegression       1.0000     0:00:26       0.7837    0.8034\n",
      "        25   SparseNormalizer RandomForest                  1.0000     0:00:38       0.7795    0.8034\n",
      "        26   MaxAbsScaler SGD                               1.0000     0:00:22       0.7148    0.8034\n",
      "        27   MaxAbsScaler LogisticRegression                1.0000     0:00:23       0.7851    0.8034\n",
      "        28   MaxAbsScaler LightGBM                          1.0000     0:00:27       0.7809    0.8034\n",
      "        29   Ensemble                                       1.0000     0:07:29       0.8048    0.8048\n"
     ]
    }
   ],
   "source": [
    "#run the training\n",
    "\n",
    "from azureml.core.experiment import Experiment\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "local_run = experiment.submit(automated_ml_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automated-ml-classification,\n",
      "Id: AutoML_bbeb1a3f-e4ca-47a5-a309-af66c25a0470_29,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('datatransformer', DataTransformer(logger=None, task=None)), ('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n",
      "               estimators=[('LogisticRegression', Pipeline(memory=None,\n",
      "     steps=[('sparsenormalizer', <automl.client.core.common.model_w...6666667, 0.06666666666666667, 0.2, 0.06666666666666667, 0.06666666666666667, 0.26666666666666666]))])\n"
     ]
    }
   ],
   "source": [
    "#get the best fitted model\n",
    "best_run, fitted_model = local_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict against the Kaggle provided test data for the Titanic\n",
    "url = \"https://raw.githubusercontent.com/TheovanKraay/mldata/master/kaggle-test.csv\"\n",
    "test = pandas.read_csv(url)\n",
    "\n",
    "testpred = test[['Sex', 'Age', 'SibSp', 'Parch', 'Embarked']]\n",
    "y_predict = fitted_model.predict(testpred.values)\n",
    "\n",
    "testpred = test[['PassengerId','Sex', 'Age', 'SibSp', 'Parch', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0    892          0       \n",
      "1    893          1       \n",
      "2    894          0       \n",
      "3    895          0       \n",
      "4    896          1       \n",
      "5    897          0       \n",
      "6    898          1       \n",
      "7    899          0       \n",
      "8    900          1       \n",
      "9    901          0       \n",
      "10   902          0       \n",
      "11   903          0       \n",
      "12   904          1       \n",
      "13   905          0       \n",
      "14   906          1       \n",
      "15   907          1       \n",
      "16   908          0       \n",
      "17   909          0       \n",
      "18   910          1       \n",
      "19   911          1       \n",
      "20   912          0       \n",
      "21   913          0       \n",
      "22   914          0       \n",
      "23   915          1       \n",
      "24   916          1       \n",
      "25   917          0       \n",
      "26   918          1       \n",
      "27   919          0       \n",
      "28   920          0       \n",
      "29   921          0       \n",
      "..   ...         ..       \n",
      "388  1280         0       \n",
      "389  1281         0       \n",
      "390  1282         0       \n",
      "391  1283         1       \n",
      "392  1284         0       \n",
      "393  1285         0       \n",
      "394  1286         0       \n",
      "395  1287         1       \n",
      "396  1288         0       \n",
      "397  1289         1       \n",
      "398  1290         0       \n",
      "399  1291         0       \n",
      "400  1292         1       \n",
      "401  1293         0       \n",
      "402  1294         1       \n",
      "403  1295         0       \n",
      "404  1296         0       \n",
      "405  1297         0       \n",
      "406  1298         0       \n",
      "407  1299         0       \n",
      "408  1300         1       \n",
      "409  1301         1       \n",
      "410  1302         1       \n",
      "411  1303         1       \n",
      "412  1304         1       \n",
      "413  1305         0       \n",
      "414  1306         1       \n",
      "415  1307         0       \n",
      "416  1308         0       \n",
      "417  1309         0       \n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#generate a submission\n",
    "sub = pandas.DataFrame()\n",
    "sub['PassengerId'] = test['PassengerId']\n",
    "sub['Survived'] = y_predict\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the submission file\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
